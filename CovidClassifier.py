# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oPt8bI0L869T5Gwj5V7Vsp_NhWzFguw_

# Transfer learning for COVID-19 diagnosis using CT images

- This cell is environment dependent. I did the project in Google Colab, so I had to mount my google drive.

- Then, I had to add my drive to valid paths so I could import data_loader.py from my drive to use.
"""

import sys
from google.colab import drive

drive.mount('/content/drive')

path = '/content/drive/MyDrive'
sys.path.append(path) if path not in sys.path else None

import warnings

warnings.filterwarnings('ignore', message='torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.')

"""## Model Creation"""

import torch
import torch.nn as nn
import torchvision.models as models

class CovidClassifier(nn.Module):
    def __init__(self, base_model='resnet18', use_pretrained=False):
        super(CovidClassifier, self).__init__()
        # Load the model with proper weights
        if base_model == 'resnet18':
            weights = models.ResNet18_Weights.IMAGENET1K_V1 if use_pretrained else None
            self.base_model = models.resnet18(weights=weights)
        else:
            weights = models.ResNet50_Weights.IMAGENET1K_V1 if use_pretrained else None
            self.base_model = models.resnet50(weights=weights)

        # Custom feature extraction and classification head
        num_features = self.base_model.fc.in_features
        self.base_model.fc = nn.Sequential(
            nn.Linear(num_features, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 2)
        )

    def forward(self, x):
        return self.base_model(x)

"""## Functions For Model Training and Evaluation"""

from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from torch.optim import Adam
from torch.optim.lr_scheduler import OneCycleLR
import numpy as np
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm

# Evaluates model's current state based on accuracy and roc-auc
def evaluate_model(model, test_loader):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    # Ensure model weights are in float32
    model = model.float()
    model.eval()

    test_preds = []
    test_true = []
    test_probs = []

    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc='Testing'):
            # Ensure inputs are in float32
            images = images.float().to(device)
            labels = labels.squeeze().to(device)

            # No need for autocast in evaluation
            outputs = model(images)
            # Get probabilities using softmax
            probs = torch.softmax(outputs, dim=1)

            # Get predicted class (0 or 1)
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            # Get probability of positive class (class 1)
            pos_probs = probs[:, 1].cpu().numpy()

            test_preds.extend(preds)
            test_true.extend(labels.cpu().numpy())
            test_probs.extend(pos_probs)

    # Convert to numpy arrays
    test_preds = np.array(test_preds)
    test_true = np.array(test_true)
    test_probs = np.array(test_probs)

    accuracy = accuracy_score(test_true, test_preds)
    auc_score = roc_auc_score(test_true, test_probs)
    report = classification_report(test_true, test_preds, target_names=['Non-COVID', 'COVID'])

    return accuracy, auc_score, report

"""**Important Note**

Part of this function saves the best model from the epochs to your file system as `best_model.pth`

Ensure that the model is being saved to the correct destination in your personal file system. It **will be needed** to reload the model at a later point.

This is not necessarry, but it could save time if you are working on a model for multiple sessions and want to ensure it is not lost.

"""

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.optim.lr_scheduler import OneCycleLR
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from tqdm.notebook import tqdm
import numpy as np
import matplotlib.pyplot as plt

def train_model(model, train_loader, val_loader, num_epochs=15):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    model = model.to(device)

    scaler = torch.amp.GradScaler()
    criterion = nn.CrossEntropyLoss()

    # Optimized learning rates for transfer learning
    optimizer = Adam([
        {'params': [p for n, p in model.named_parameters() if 'fc' not in n], 'lr': 1e-4},
        {'params': model.base_model.fc.parameters(), 'lr': 1e-3}
    ])

    # One Cycle learning rate scheduler
    scheduler = OneCycleLR(
        optimizer,
        max_lr=[1e-4, 1e-3],
        steps_per_epoch=len(train_loader),
        epochs=num_epochs,
        pct_start=0.3,
        div_factor=25.0,
        final_div_factor=1e4
    )

    best_val_acc = 0
    best_val_auc = 0
    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [],
              'val_auc': [], 'learning_rates': []}

    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch+1}/{num_epochs}')

        current_lr = optimizer.param_groups[0]['lr']
        print(f'Current learning rate: {current_lr:.2e}')

        # Training phase
        model.train()
        train_losses = []
        train_preds = []
        train_true = []

        for images, labels in tqdm(train_loader, desc='Training'):
            images = images.to(device)
            labels = labels.squeeze().long().to(device)  # Convert to long tensor for CrossEntropyLoss

            optimizer.zero_grad()

            with torch.amp.autocast(str(device.type)):
                outputs = model(images)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            scheduler.step()
            scaler.step(optimizer)
            scaler.update()

            train_losses.append(loss.item())
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            train_preds.extend(preds)
            train_true.extend(labels.cpu().numpy())

        train_loss = np.mean(train_losses)
        train_acc = accuracy_score(train_true, train_preds)

        # Validation phase
        model.eval()
        val_losses = []
        val_preds = []
        val_true = []
        val_probs = []

        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                labels = labels.squeeze().long().to(device)

                with torch.amp.autocast(str(device.type)):
                    outputs = model(images)
                    loss = criterion(outputs, labels)

                val_losses.append(loss.item())
                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Probability of positive class
                preds = (probs > 0.5).astype(int)
                val_preds.extend(preds)
                val_true.extend(labels.cpu().numpy())
                val_probs.extend(probs)

        val_loss = np.mean(val_losses)
        val_acc = accuracy_score(val_true, val_preds)
        val_auc = roc_auc_score(val_true, val_probs)

        # Save best model
        if val_acc > best_val_acc or (val_acc == best_val_acc and val_auc > best_val_auc):
            best_val_acc = val_acc
            best_val_auc = val_auc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_acc': val_acc,
                'val_auc': val_auc
            }, '/content/drive/MyDrive/best_model.pth')

        # Update history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)
        history['val_auc'].append(val_auc)
        history['learning_rates'].append(current_lr)

        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')
        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}')

        if epoch != 0 and epoch % 5 == 0:
            plot_training_history(history)
            plt.show()

    return history

# Plot current training progress of model
def plot_training_history(history):
    plt.figure(figsize=(20, 5))

    plt.subplot(1, 4, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Val Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 4, 2)
    plt.plot(history['train_acc'], label='Train Acc')
    plt.plot(history['val_acc'], label='Val Acc')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 4, 3)
    plt.plot(history['val_auc'], label='Val AUC')
    plt.title('Validation AUC-ROC')
    plt.xlabel('Epoch')
    plt.ylabel('AUC')
    plt.legend()

    plt.subplot(1, 4, 4)
    plt.plot(history['learning_rates'], label='LR')
    plt.title('Learning Rate')
    plt.xlabel('Epoch')
    plt.ylabel('Learning Rate')
    plt.yscale('log')
    plt.legend()

    plt.tight_layout()

"""## Nerual Network Trained From Scratch

### Training
"""

from data_loader import get_dataloader

# Load data
train_loader, val_loader, test_loader = get_dataloader(path='/content/drive/MyDrive/S224/')

# Train model from scratch
model_scratch = CovidClassifier(use_pretrained=False)
history_scratch = train_model(model_scratch, train_loader, val_loader)

"""### Saving & Reloading Best Model

This process depends on your local machine and runtime environment. Specify the path as needed to ensure this functions correctly.
"""

import os
# best_mode.pth gets overwritten each time train_model is called, move model to permanent destination
os.rename('/content/drive/MyDrive/best_model.pth', '/content/drive/MyDrive/best_model_scratch.pth')

# Load Best Preforming model
best_model_scratch = CovidClassifier(use_pretrained=False)
checkpoint = torch.load('/content/drive/MyDrive/best_model_scratch.pth')
best_model_scratch.load_state_dict(checkpoint['model_state_dict'])

"""### Analyzing Preformance"""

# Evaluate scratch model
accuracy_scratch, auc_scratch, report_scratch = evaluate_model(best_model_scratch, test_loader)
print("\nModel trained from scratch:")
print(f"Test Accuracy: {accuracy_scratch:.4f}")
print("Classification Report:")
print(report_scratch)

"""## Neural Network Using Transfer Learning

### Training
"""

# 2. Training with transfer learning
model_transfer = CovidClassifier(use_pretrained=True,)
history_transfer = train_model(model_transfer, train_loader, val_loader)

"""### Saving & Reloading Best Model

This process depends on your local machine and runtime environment. Specify the path as needed to ensure this functions correctly.
"""

os.rename('/content/drive/MyDrive/best_model.pth', '/content/drive/MyDrive/best_model_transfer.pth')

best_model_transfer = CovidClassifier(use_pretrained=True)
checkpoint = torch.load('/content/drive/MyDrive/best_model_transfer.pth')
best_model_transfer.load_state_dict(checkpoint['model_state_dict'])

"""### Preformance Analysis"""

accuracy_transfer, auc_transfer, report_transfer = evaluate_model(best_model_transfer, test_loader)
print("\nModel trained with transfer learning:")
print(f"Test Accuracy: {accuracy_transfer:.4f}")
print("Classification Report:")
print(report_transfer)

"""## Analysis Using Comprehensive Visualizations

Colab didn't have this installed.
"""

# Run this cell to install
!pip install grad-cam

"""These are functions that will be utilized by both visualization techniques"""

import skimage
import pandas as pd
import numpy as np
import random

def get_random_samples(num_samples=10):
    """
    Get random samples from test set, balanced between COVID and non-COVID.

    Args:
        num_samples: Total number of samples to select (half COVID, half non-COVID)
    Returns:
        List of selected filenames
    """
    # Read test.csv to get filenames
    df = pd.read_csv('/content/drive/MyDrive/S224/test.csv')

    # Get equal numbers of COVID and non-COVID samples
    samples_per_class = num_samples // 2
    covid_samples = random.sample(list(df[df['label'] == 1]['filename'].values), samples_per_class)
    non_covid_samples = random.sample(list(df[df['label'] == 0]['filename'].values), samples_per_class)

    # Combine samples
    selected_samples = covid_samples + non_covid_samples
    random.shuffle(selected_samples)  # Shuffle to mix classes

    return selected_samples

def prepare_image_for_display(image_tensor):
    """Convert tensor to numpy array in correct format for display."""
    # Convert to numpy and transpose from (C,H,W) to (H,W,C)
    image_np = image_tensor.cpu().numpy()
    image_np = np.transpose(image_np, (1, 2, 0))

    # If grayscale (image was expanded to 3 identical channels)
    if np.allclose(image_np[:,:,0], image_np[:,:,1]) and np.allclose(image_np[:,:,1], image_np[:,:,2]):
        image_np = image_np[:,:,0]

    # Normalize to [0,1] range
    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())

    return image_np

def analyze_results(results_df):
    """
    Analyze and print detailed results from the visualizations.

    Args:
        results_df: DataFrame containing visualization results
    """
    print("\nDetailed Analysis:")

    # Class-wise performance
    print("\nClass-wise Performance:")
    for label in [0, 1]:
        class_results = results_df[results_df['true_label'] == label]
        correct = class_results['correct'].sum()
        total = len(class_results)
        class_name = "COVID" if label == 1 else "Non-COVID"
        print(f"{class_name}:")
        print(f"  Accuracy: {correct}/{total} ({100*correct/total:.1f}%)")
        print(f"  Average Confidence: {class_results['confidence'].mean():.1f}%")

    # Confidence analysis
    print("\nConfidence Analysis:")
    print(f"Average confidence (correct predictions): {results_df[results_df['correct']]['confidence'].mean():.1f}%")
    print(f"Average confidence (incorrect predictions): {results_df[~results_df['correct']]['confidence'].mean():.1f}%")

# Get a set of random samples that will be used for all visualizations
selected_samples = get_random_samples(num_samples=20)  # 10 COVID, 10 non-COVID
selected_samples

"""### GradCAM

#### Core Code
"""

import torch
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F

def visualize_single_gradcam(model, image, label, save_path=None, temperature=4.0):
    """
    Generate and display GradCAM visualization for a single image with confidence scores.

    Args:
        model: The trained model
        image: Input image as tensor (should be in shape [C,H,W])
        label: True label (0 for Non-COVID, 1 for COVID)
        save_path: Optional path to save the visualization
        temperature: Scaling factor for logits (higher = softer predictions)
    """
    # Setup
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()

    # Get the target layer
    target_layer = model.base_model.layer4[-1]

    # Initialize GradCAM
    cam = GradCAM(model=model, target_layers=[target_layer])

    # Prepare image and get model prediction
    input_tensor = image.unsqueeze(0).float().to(device)

    with torch.no_grad():
        # Get raw logits
        outputs = model(input_tensor)

        # Apply temperature scaling to logits before softmax
        scaled_outputs = outputs / temperature

        # Calculate probabilities
        probs = F.softmax(scaled_outputs, dim=1)
        pred = torch.argmax(outputs, dim=1).item()

        # Get probabilities for both classes
        prob_negative = probs[0][0].item() * 100
        prob_positive = probs[0][1].item() * 100

        # Get confidence for predicted class
        confidence = probs[0][pred].item() * 100

    # Generate GradCAM
    grayscale_cam = cam(input_tensor=input_tensor)
    grayscale_cam = grayscale_cam[0]

    # Create visualization
    plt.figure(figsize=(15, 5))

    # Plot original image
    orig_img = prepare_image_for_display(image)
    plt.subplot(1, 3, 1)
    plt.imshow(orig_img, cmap='gray')
    plt.title(f'True Label: {"COVID" if label == 1 else "Non-COVID"}\nPrediction: {"COVID" if pred == 1 else "Non-COVID"} ({confidence:.1f}%)')
    plt.axis('off')

    # Plot heatmap
    plt.subplot(1, 3, 2)
    plt.imshow(grayscale_cam, cmap='jet')
    plt.title('GradCAM Heatmap')
    plt.axis('off')

    # Plot overlay
    plt.subplot(1, 3, 3)
    if len(orig_img.shape) == 2:
        # Handle grayscale images
        orig_img_normalized = (orig_img - orig_img.min()) / (orig_img.max() - orig_img.min())
        overlay = np.stack([orig_img_normalized] * 3, axis=-1)
    else:
        # Handle RGB images
        overlay = (orig_img - orig_img.min()) / (orig_img.max() - orig_img.min())

    # Create heatmap overlay
    heatmap = plt.cm.jet(grayscale_cam)[:, :, :3]

    # Combine original image and heatmap
    superimposed = (0.6 * overlay + 0.4 * heatmap)
    superimposed = np.clip(superimposed, 0, 1)

    plt.imshow(superimposed)
    plt.title('Overlay')
    plt.axis('off')

    # Finalize and display
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.show()

    return pred, confidence, prob_negative, prob_positive

def visualize_multiple_gradcam(model, selected_samples, temperature=4.0):
    """
    Generate GradCAM visualizations for specified samples using matplotlib.

    Args:
        model: The trained model
        selected_samples: List of filenames to visualize
        temperature: Temperature scaling for confidence
    """
    results = []
    base_path = '/content/drive/MyDrive/S224/'

    for i, filename in enumerate(selected_samples):
        # Load image
        img = skimage.io.imread(base_path + filename)
        img = skimage.util.img_as_float32(img)
        img = img.reshape(1, img.shape[0], img.shape[1])
        img = torch.tensor(img, dtype=torch.float32)
        img = img.expand(3, img.shape[1], img.shape[2])

        # Get true label from filename
        label = 1 if 'COVID' in filename else 0

        print(f"\nProcessing image {i+1}/{len(selected_samples)}: {filename}")

        # Generate visualization
        pred, conf, prob_neg, prob_pos = visualize_single_gradcam(
            model, img, label, temperature=temperature
        )

        # Store results
        results.append({
            'filename': filename,
            'true_label': label,
            'predicted_label': pred,
            'confidence': conf,
            'prob_negative': prob_neg,
            'prob_positive': prob_pos,
            'correct': pred == label,
            'method': 'GradCAM'
        })

    # Print summary
    print("\nGradCAM Summary:")
    print(f"Total samples: {len(selected_samples)}")
    correct = sum(1 for r in results if r['correct'])
    print(f"Correct predictions: {correct}/{len(selected_samples)} ({100*correct/len(selected_samples):.1f}%)")

    # Create DataFrame for easy analysis
    results_df = pd.DataFrame(results)
    return results_df

"""#### Scratch Model"""

# Generate visualizations for scratch model
print("Generating visualizations for model trained from scratch:")
results_scratch = visualize_multiple_gradcam(
    best_model_scratch,
    selected_samples=selected_samples,
    temperature=4.0
)

analyze_results(results_scratch)

"""#### Transfer Learning Model"""

results_transfer = visualize_multiple_gradcam(
    best_model_transfer,
    selected_samples=selected_samples,
    temperature=4.0
)

analyze_results(results_transfer)

"""### EigenCAM

#### Core Code
"""

import torch
from pytorch_grad_cam import EigenCAM
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F

def visualize_single_eigencam(model, image, label, save_path=None, temperature=4.0):
    """
    Generate and display EigenCAM visualization for a single image with confidence scores.

    Args:
        model: The trained model
        image: Input image as tensor (should be in shape [C,H,W])
        label: True label (0 for Non-COVID, 1 for COVID)
        save_path: Optional path to save the visualization
        temperature: Scaling factor for logits (higher = softer predictions)
    """
    # Setup
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()

    # Get the target layer (same as GradCAM)
    target_layer = model.base_model.layer4[-1]

    # Initialize EigenCAM
    cam = EigenCAM(model=model, target_layers=[target_layer])

    # Prepare image and get model prediction
    input_tensor = image.unsqueeze(0).float().to(device)

    with torch.no_grad():
        # Get raw logits
        outputs = model(input_tensor)

        # Apply temperature scaling to logits before softmax
        scaled_outputs = outputs / temperature

        # Calculate probabilities
        probs = F.softmax(scaled_outputs, dim=1)
        pred = torch.argmax(outputs, dim=1).item()

        # Get probabilities for both classes
        prob_negative = probs[0][0].item() * 100
        prob_positive = probs[0][1].item() * 100

        # Get confidence for predicted class
        confidence = probs[0][pred].item() * 100

    # Generate EigenCAM
    grayscale_cam = cam(input_tensor=input_tensor)
    grayscale_cam = grayscale_cam[0]

    # Create visualization
    plt.figure(figsize=(15, 5))

    # Plot original image
    orig_img = prepare_image_for_display(image)
    plt.subplot(1, 3, 1)
    plt.imshow(orig_img, cmap='gray')
    plt.title(f'True Label: {"COVID" if label == 1 else "Non-COVID"}\nPrediction: {"COVID" if pred == 1 else "Non-COVID"} ({confidence:.1f}%)')
    plt.axis('off')

    # Plot heatmap
    plt.subplot(1, 3, 2)
    plt.imshow(grayscale_cam, cmap='jet')
    plt.title('EigenCAM Heatmap')
    plt.axis('off')

    # Plot overlay
    plt.subplot(1, 3, 3)
    if len(orig_img.shape) == 2:
        # Handle grayscale images
        orig_img_normalized = (orig_img - orig_img.min()) / (orig_img.max() - orig_img.min())
        overlay = np.stack([orig_img_normalized] * 3, axis=-1)
    else:
        # Handle RGB images
        overlay = (orig_img - orig_img.min()) / (orig_img.max() - orig_img.min())

    # Create heatmap overlay
    heatmap = plt.cm.jet(grayscale_cam)[:, :, :3]

    # Combine original image and heatmap
    superimposed = (0.6 * overlay + 0.4 * heatmap)
    superimposed = np.clip(superimposed, 0, 1)

    plt.imshow(superimposed)
    plt.title('Overlay')
    plt.axis('off')

    # Finalize and display
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.show()

    return pred, confidence, prob_negative, prob_positive

def test_eigencam_single_sample(model, test_loader):
    """
    Test EigenCAM visualization on a single sample from the test set.

    Args:
        model: The trained model
        test_loader: DataLoader containing test data
    """
    # Get a single batch
    images, labels = next(iter(test_loader))

    # Take the first image from the batch
    image = images[0]
    label = labels[0].item()

    # Generate and display visualization
    pred, conf, prob_neg, prob_pos = visualize_single_eigencam(
        model, image, label, temperature=4.0
    )

    print("\nResults:")
    print(f"True Label: {'COVID' if label == 1 else 'Non-COVID'}")
    print(f"Predicted: {'COVID' if pred == 1 else 'Non-COVID'}")
    print(f"Confidence: {conf:.1f}%")
    print(f"Probability of Non-COVID: {prob_neg:.1f}%")
    print(f"Probability of COVID: {prob_pos:.1f}%")

import torch
from pytorch_grad_cam import EigenCAM
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F

def visualize_multiple_eigencam(model, selected_samples, temperature=4.0):
    """
    Generate EigenCAM visualizations for specified samples using matplotlib.

    Args:
        model: The trained model
        selected_samples: List of filenames to visualize
        temperature: Temperature scaling for confidence
    """
    results = []
    base_path = '/content/drive/MyDrive/S224/'

    for i, filename in enumerate(selected_samples):
        # Load image
        img = skimage.io.imread(base_path + filename)
        img = skimage.util.img_as_float32(img)
        img = img.reshape(1, img.shape[0], img.shape[1])
        img = torch.tensor(img, dtype=torch.float32)
        img = img.expand(3, img.shape[1], img.shape[2])

        # Get true label from filename
        label = 1 if 'COVID' in filename else 0

        print(f"\nProcessing image {i+1}/{len(selected_samples)}: {filename}")

        # Generate visualization using EigenCAM
        pred, conf, prob_neg, prob_pos = visualize_single_eigencam(
            model, img, label, temperature=temperature
        )

        # Store results
        results.append({
            'filename': filename,
            'true_label': label,
            'predicted_label': pred,
            'confidence': conf,
            'prob_negative': prob_neg,
            'prob_positive': prob_pos,
            'correct': pred == label,
            'method': 'EigenCAM'
        })

    # Print summary
    print("\nEigenCAM Summary:")
    print(f"Total samples: {len(selected_samples)}")
    correct = sum(1 for r in results if r['correct'])
    print(f"Correct predictions: {correct}/{len(selected_samples)} ({100*correct/len(selected_samples):.1f}%)")

    # Create DataFrame for easy analysis
    results_df = pd.DataFrame(results)
    return results_df

"""#### Scratch Model"""

results_scratch = visualize_multiple_eigencam(
    best_model_scratch,
    selected_samples=selected_samples,
    temperature=4.0
)

analyze_results(results_scratch)

"""#### Transfer Learning Model"""

results_transfer = visualize_multiple_eigencam(
    best_model_transfer,
    selected_samples=selected_samples,
    temperature=4.0
)

analyze_results(results_transfer)

"""## Conclusion

The comparative analysis demonstrates that transfer learning offers significant advantages over training from scratch for COVID-19 CT image classification. Despite the domain difference between natural images (ImageNet) and medical CT scans, the pre-trained weights provided valuable feature extraction capabilities that transferred effectively to this medical imaging task.

The success of this approach suggests that transfer learning should be considered as a primary strategy when developing similar medical imaging applications, particularly when working with limited datasets or when rapid deployment is necessary.

Next Steps to consider would be trying to incorporate more domain-specific medical pretraining, or Exploring the impact of different pre-training data sets.
"""